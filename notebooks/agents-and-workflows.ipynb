{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents and Workflows\n",
    "## Building Intelligent Systems with Spring AI\n",
    "\n",
    "**Spring AI Workshop - Session #3**\n",
    "*November 20, 2025*\n",
    "\n",
    "**Speaker:** Ketevan Khachapuridze\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. **Core Concepts:** Agents, Workflows, and Building Blocks\n",
    "2. **Decision Guide:** When to Use What\n",
    "3. **Workflow Patterns:**\n",
    "   - Chain Workflow\n",
    "   - Routing Workflow\n",
    "   - Parallelisation Workflow\n",
    "   - Orchestrator-Workers\n",
    "   - Evaluator-Optimizer\n",
    "4. **Autonomous Agents**\n",
    "5. **Building Reliable Systems:** Testing and Guardrails\n",
    "6. **VoyagerMate Case Study:** Applied Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts: Agents vs Workflows\n",
    "\n",
    "[Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)\n",
    "\n",
    "**Agentic Systems** is an umbrella term for systems where LLMs actively reason, plan, and use tools to solve problems. These systems generally fall into two categories: **Workflows** and **Agents**.\n",
    "\n",
    "### Workflows\n",
    "Workflows are systems where the steps are predefined. The path is predictable and orchestrated by code.\n",
    "- **You** decide the steps.\n",
    "- **Code** controls the flow.\n",
    "- The LLM **executes** each step.\n",
    "- They are **reliable** and **testable**.\n",
    "\n",
    "### Agents\n",
    "Agents are systems where the LLM dynamically controls the process.\n",
    "- The **LLM** decides the steps.\n",
    "- The **LLM** controls the flow.\n",
    "- The LLM **plans** and **adapts**.\n",
    "- They are **flexible** but **less predictable**.\n",
    "\n",
    "### The Impact of Reasoning Models\n",
    "Modern \"Reasoning Models\" (like OpenAI o1 or Claude 3.7) have internalized many complex behaviors, using \"Chain of Thought\" to think before they answer.\n",
    "- **Micro-Reasoning:** You often do not need complex prompts just to get the model to think step-by-step. The model does this automatically.\n",
    "- **Self-Correction:** These models can often catch their own errors.\n",
    "\n",
    "However, workflows remain essential for **Macro-Orchestration**: breaking down tasks that are too large for a single context window, require parallel execution, or involve distinct external actions.\n",
    "\n",
    "### The Building Blocks\n",
    "\n",
    "Both workflows and agents are built from the same foundation: an LLM enhanced with three key capabilities.\n",
    "\n",
    "1. **Retrieve:** Generate search queries to find information.\n",
    "2. **Use Tools:** Call external functions to act on the world.\n",
    "3. **Remember:** Read and write context to memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    User[User] --> LLM[\"LLM / Model\"]\n",
    "    subgraph Capabilities\n",
    "        LLM <--> Tools[Tools]\n",
    "        LLM <--> Memory[Memory]\n",
    "        LLM <--> RAG[\"Retrieval / RAG\"]\n",
    "    end\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Guide: When to Use Which?\n",
    "\n",
    "> **Golden Rule:** Start simple. Only add autonomy when it is necessary.\n",
    "\n",
    "### Use Workflows when...\n",
    "You know the steps in advance. It is like following a recipe.\n",
    "- The sequence of steps is fixed.\n",
    "- Inputs and outputs are predictable.\n",
    "- You need the same result every time.\n",
    "\n",
    "**Example:** Converting user input to structured data. The steps (extract, validate, save) are always the same.\n",
    "\n",
    "### Use Agents when...\n",
    "The path depends on what you discover. It is like a detective investigating a case.\n",
    "- You do not know the steps beforehand.\n",
    "- Each action depends on previous findings.\n",
    "- The solution requires exploration.\n",
    "\n",
    "**Example:** A code debugging assistant. The agent must read the error, search code, and test hypotheses based on what it finds.\n",
    "\n",
    "### Strategic Insights\n",
    "- **Start with deterministic workflows** before escalating to autonomous agents.\n",
    "- **Reliability levers** include tool design discipline, memory externalisation (vector or relational stores), and proactive context compaction to avoid \"context rot.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 1: Chain Workflow\n",
    "\n",
    "**Prompt chaining** breaks a complex task into smaller, ordered steps. Each step uses the result of the previous one.\n",
    "\n",
    "### When to Use\n",
    "While reasoning models handle internal logic well, this pattern is ideal when:\n",
    "- Steps involve **external actions** (e.g., API calls) that must happen in order.\n",
    "- You need to **checkpoint state** or validate output between steps.\n",
    "- You need to force a specific, audible process structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Input[Input] --> Step1[\"Step 1: Extract\"]\n",
    "    Step1 --> Step2[\"Step 2: Validate\"]\n",
    "    Step2 --> Step3[\"Step 3: Summarize\"]\n",
    "    Step3 --> Output[Output]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring AI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class ChainWorkflow {\n",
    "    private final ChatClient chatClient;\n",
    "    private final String[] systemPrompts;\n",
    "\n",
    "    // Processes input through a series of prompts,\n",
    "    // where the output of each step becomes the input for the next.\n",
    "    public String chain(String userInput) {\n",
    "        String response = userInput;\n",
    "        for (String prompt : systemPrompts) {\n",
    "            // Combine the system prompt with previous response\n",
    "            String input = String.format(\"{%s}\\n{%s}\", prompt, response);\n",
    "            // Process through the LLM and capture output\n",
    "            response = chatClient.prompt(input).call().content();\n",
    "        }\n",
    "        return response;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 2: Routing Workflow\n",
    "\n",
    "**Routing** uses an LLM to classify an input and direct it to the correct specialized process. Instead of one model handling everything, a router selects the best tool or workflow.\n",
    "\n",
    "### When to Use\n",
    "- **Cost Optimization:** Route difficult tasks to expensive reasoning models and simple tasks to cheaper, faster models.\n",
    "- **Specialization:** Different tools or models perform better on specific subtasks.\n",
    "- **Separation of Concerns:** Separate decision-making from execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Input[Input] --> Router[\"Router LLM\"]\n",
    "    Router -->|Intent A| RouteA[\"Specialist A\"]\n",
    "    Router -->|Intent B| RouteB[\"Specialist B\"]\n",
    "    Router -->|Intent C| RouteC[\"Specialist C\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring AI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Autowired\n",
    "private ChatClient chatClient;\n",
    "\n",
    "// Create the workflow\n",
    "RoutingWorkflow workflow = new RoutingWorkflow(chatClient);\n",
    "\n",
    "// Define specialized prompts for each category\n",
    "Map<String, String> routes = Map.of(\n",
    "    \"billing\", \"You are a billing specialist. Help resolve billing issues...\",\n",
    "    \"technical\", \"You are a technical support engineer. Help solve technical problems...\",\n",
    "    \"general\", \"You are a customer service representative. Help with general inquiries...\"\n",
    ");\n",
    "\n",
    "// Route the input\n",
    "String input = \"My account was charged twice last week\";\n",
    "String response = workflow.route(input, routes);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 3: Parallelization Workflow\n",
    "\n",
    "**Parallelization** runs multiple LLM calls at the same time. The results are then combined or compared. This is useful for \"Sectioning\" (splitting a task) or \"Voting\" (getting multiple opinions).\n",
    "\n",
    "### When to Use\n",
    "- **Latency Reduction:** Reasoning models can be slow. Parallelization offsets this by running independent tasks concurrently.\n",
    "- **Scale:** The task can be split into independent parts.\n",
    "- **Confidence:** Multiple viewpoints increase accuracy (voting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Input[Input] --> Split{Split}\n",
    "    Split --> TaskA[\"Task A\"]\n",
    "    Split --> TaskB[\"Task B\"]\n",
    "    Split --> TaskC[\"Task C\"]\n",
    "    TaskA --> Join{Aggregator}\n",
    "    TaskB --> Join\n",
    "    TaskC --> Join\n",
    "    Join --> Output[Output]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring AI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List<String> parallelResponse = new ParallelizationWorkflow(chatClient)\n",
    "    .parallel(\n",
    "        \"Analyze how market changes will impact this stakeholder group.\",\n",
    "        List.of(\n",
    "            \"Customers: ...\",\n",
    "            \"Employees: ...\",\n",
    "            \"Investors: ...\",\n",
    "            \"Suppliers: ...\"\n",
    "        ),\n",
    "        4\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 4: Orchestrator-Workers\n",
    "\n",
    "In this pattern, a central **Orchestrator LLM** breaks a task into subtasks and assigns them to **Worker LLMs**. The orchestrator then synthesizes the results. Unlike parallelization, the orchestrator dynamically decides the plan.\n",
    "\n",
    "### When to Use\n",
    "- The task is complex (e.g., \"Write a full software module\") and exceeds a single model's capacity.\n",
    "- The subtasks cannot be predicted in advance.\n",
    "- You need to combine results from different perspectives or tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    Task[\"Complex Task\"] --> Orchestrator[\"Orchestrator LLM\"]\n",
    "    Orchestrator -->|Plan & Delegate| Worker1[\"Worker 1\"]\n",
    "    Orchestrator -->|Plan & Delegate| Worker2[\"Worker 2\"]\n",
    "    Worker1 -->|Result| Orchestrator\n",
    "    Worker2 -->|Result| Orchestrator\n",
    "    Orchestrator -->|Synthesize| Output[\"Final Result\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring AI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class OrchestratorWorkersWorkflow {\n",
    "\n",
    "    public WorkerResponse process(String taskDescription) {\n",
    "        // 1. Orchestrator analyzes task and determines subtasks\n",
    "        OrchestratorResponse orchestratorResponse = // ...\n",
    "\n",
    "        // 2. Workers process subtasks in parallel\n",
    "        List<String> workerResponses = // ...\n",
    "\n",
    "        // 3. Results are combined into a final response\n",
    "        return new WorkerResponse(/* ... */);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 5: Evaluator-Optimizer\n",
    "\n",
    "This workflow creates a feedback loop. One LLM (the **Generator**) creates a draft, and another LLM (the **Evaluator**) reviews it. The Generator then improves the draft based on the feedback.\n",
    "\n",
    "### When to Use\n",
    "- **External Verification:** Reasoning models self-correct well, but this pattern is vital for checking against **external ground truths** (e.g., \"Code must compile\", \"Policy check passed\").\n",
    "- You have clear, objective criteria for quality.\n",
    "- Iteration typically improves the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    Input[Task] --> Generator[\"Generator LLM\"]\n",
    "    Generator --> Draft[Draft]\n",
    "    Draft --> Evaluator[\"Evaluator LLM\"]\n",
    "    Evaluator -->|Feedback| Generator\n",
    "    Evaluator -->|Approved| Output[\"Final Output\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring AI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class EvaluatorOptimizerWorkflow {\n",
    "    public RefinedResponse loop(String task) {\n",
    "        // 1. Generate initial solution\n",
    "        Generation generation = generate(task, context);\n",
    "        \n",
    "        // 2. Evaluate the solution\n",
    "        EvaluationResponse evaluation = evaluate(generation.response(), task);\n",
    "        \n",
    "        // 3. If PASS, return solution\n",
    "        // 4. If NEEDS_IMPROVEMENT, incorporate feedback and generate new solution\n",
    "        // 5. Repeat until satisfactory\n",
    "        return new RefinedResponse(finalSolution, chainOfThought);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous Agents\n",
    "\n",
    "Agents handle tasks that do not fit a fixed workflow. An agent starts with a goal, creates a plan, acts, and observes the results. It loops through this process until the goal is met.\n",
    "\n",
    "### When to Use\n",
    "- The task is open-ended.\n",
    "- The number of steps is variable.\n",
    "- The environment provides feedback (like code execution or API results).\n",
    "\n",
    "## Multi-Agent Systems\n",
    "\n",
    "Multi-agent systems use teams of specialized agents. Each agent focuses on one job (e.g., research, writing, review) and they coordinate to solve larger problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    User[User] --> AgentA[\"Agent A (Leader)\"]\n",
    "    AgentA <--> AgentB[\"Agent B (Researcher)\"]\n",
    "    AgentA <--> AgentC[\"Agent C (Writer)\"]\n",
    "    AgentB <--> AgentC\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Reliable Systems\n",
    "\n",
    "Building effective agentic systems requires more than just prompts. You need a solid engineering foundation.\n",
    "\n",
    "### Spring AI Advantages\n",
    "- **Model Portability:** Switch models easily using dependencies.\n",
    "- **Structured Output:** Map LLM responses directly to Java objects (DTOs).\n",
    "- **Consistent API:** Use a uniform interface for different providers.\n",
    "\n",
    "### Guardrails and Testing\n",
    "You must ensure your system is safe and predictable.\n",
    "\n",
    "1.  **Guardrails:** Define what the system can and cannot do.\n",
    "    -   Use **Structured Outputs** to enforce response formats.\n",
    "    -   Sanitize inputs and outputs.\n",
    "    -   Set rate limits and retry policies.\n",
    "2.  **Testing:**\n",
    "    -   **Unit Tests:** Test routing and logic components.\n",
    "    -   **Prompt Tests:** Verify LLM behavior with test suites.\n",
    "    -   **Golden Responses:** Compare outputs against known good examples.\n",
    "3.  **Observability:** Use structured logging to track tool calls and iterations.\n",
    "\n",
    "### Key Recommendations\n",
    "1.  **Start Simple:** Begin with basic workflows. Add complexity only when needed.\n",
    "2.  **Use Reasoning Models for Logic:** Let the model handle \"micro-reasoning\" internally. Use workflows for \"macro-orchestration.\"\n",
    "3.  **Design Good Tools:** Ensure your tools are well-documented and reliable.\n",
    "4.  **Balance Trade-offs:** More iterations improve quality but increase latency and cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    Start[\"Start Simple\"] --> Analyze{Needs?}\n",
    "    Analyze -->|Predictable| Workflow[Workflow]\n",
    "    Analyze -->|Open-ended| Agent[Agent]\n",
    "    Workflow --> Test[\"Test & Iterate\"]\n",
    "    Agent --> Guardrails[\"Add Guardrails\"]\n",
    "    Guardrails --> Test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VoyagerMate Case Study: Applied Patterns\n",
    "\n",
    "We have implemented these patterns in **VoyagerMate** to handle the complexity of travel planning.\n",
    "\n",
    "### 1. Chain Workflow (The Foundation)\n",
    "**Implementation:** `ItineraryWorkflowService`\n",
    "We use a four-step deterministic chain (Identify -> Plan -> Budget -> Summary). This ensures every trip plan has these essential components regardless of the LLM's creative variations. It is the reliable backbone of the system.\n",
    "\n",
    "### 2. Routing Workflow (The Concierge)\n",
    "**Implementation:** `VoyagerRoutingWorkflowService`\n",
    "We classify user prompts into intents like `CONCIERGE`, `BOOKING_CHANGE`, or `TRAVEL_RISK`. This allows us to use a fast model for simple chats and a deeper reasoning model (or a specialized prompt) for risk assessment or complex modifications.\n",
    "\n",
    "### 3. Parallelization Workflow (The Research Sweep)\n",
    "**Implementation:** `ParallelItineraryWorkflowService`\n",
    "Trip planning involves checking lodging, dining, and logistics simultaneously. We use Java's `CompletableFuture` and Virtual Threads to run concurrent research tracks. This significantly reduces the total latency compared to checking each category sequentially.\n",
    "\n",
    "### 4. Orchestrator-Workers (The Planner)\n",
    "**Implementation:** `OrchestratorWorkersWorkflowService`\n",
    "For vague requests like \"Plan a sabbatical,\" we cannot use a fixed chain. An Orchestrator LLM breaks the brief down into specific subtasks (Visa Check, Accommodation, Experiences) and delegates them to specialized Worker LLMs (via `VoyagerTools`). It then synthesizes their findings into a cohesive narrative.\n",
    "\n",
    "### 5. Evaluator-Optimizer (The Reviewer)\n",
    "**Implementation:** `ItineraryRefinementWorkflowService`\n",
    "When generating detailed itineraries, quality matters. We use a generator model to create a draft, and a separate \"Critic\" model to review it for feasibility and budget constraints. The generator refines the plan based on this feedback, ensuring the final output is realistic.\n",
    "\n",
    "### 6. Multi-Agent System (The Team)\n",
    "**Implementation:** `MultiAgentOrchestratorService`\n",
    "We use the **Agents-as-Tools** pattern to coordinate a team of specialists. A Lead Orchestrator LLM is equipped with specialized tools (`ask_logistics_expert`, `ask_accommodation_expert`, `ask_activity_expert`). When the Orchestrator needs specific details, it calls these tools, which in turn spin up their own specialized LLM sessions. The Orchestrator then synthesizes these expert contributions into a final plan. This demonstrates how to compose multiple agents into a cohesive system using standard tool-calling mechanisms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "java",
   "pygments_lexer": "java",
   "version": "21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}