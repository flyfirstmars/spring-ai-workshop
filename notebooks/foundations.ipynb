{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Augmented LLM Foundations with Spring AI\n\n## About This Notebook\n\nThis is an educational companion to the VoyagerMate implementation in /src. \n\n**How to use this notebook:**\n- Theory and Concepts: Each section explains Spring AI concepts\n- Demo Code: Runnable examples demonstrate the concepts\n- Reference to /src: Links to actual VoyagerMate implementation\n- Learn by doing: Execute cells, modify parameters, experiment\n\n**The actual implementation:**\n- `/src/main/java/...` contains the working VoyagerMate application\n- Shell commands in `VoyagerMateCommands.java` show production usage\n- Services in `VoyagerMateService.java` implement real workflows\n- This notebook helps you understand the why and how behind that code\n\nSpring AI applies familiar Spring patterns to large language models (LLMs), making it practical to build production-ready AI services in Java. VoyagerMate, a travel concierge example, demonstrates how these concepts translate into a domain-specific product."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Dependencies\n",
    "\n",
    "First, let's set up our environment with Spring AI dependencies. In Kotlin Notebooks, we use `@file:DependsOn` to import Maven dependencies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:12:15.140957Z",
     "start_time": "2025-10-18T08:12:09.572538Z"
    }
   },
   "source": "// Dependencies matching pom.xml\n@file:DependsOn(\"org.springframework.ai:spring-ai-starter-model-azure-openai:1.0.3\")\n@file:DependsOn(\"org.springframework.boot:spring-boot-starter-web:3.5.6\")\n@file:DependsOn(\"org.springframework.retry:spring-retry:2.0.11\")\n\n// Spring AI imports\nimport org.springframework.ai.chat.client.ChatClient\nimport org.springframework.ai.chat.client.ChatClientResponse\nimport org.springframework.ai.chat.messages.AssistantMessage\nimport org.springframework.ai.chat.messages.SystemMessage\nimport org.springframework.ai.chat.messages.UserMessage\nimport org.springframework.ai.chat.model.ChatResponse\nimport org.springframework.ai.chat.prompt.Prompt\nimport org.springframework.ai.chat.prompt.PromptTemplate\nimport org.springframework.ai.chat.prompt.SystemPromptTemplate\nimport org.springframework.ai.azure.openai.AzureOpenAiChatModel\nimport org.springframework.ai.azure.openai.AzureOpenAiChatOptions\nimport org.springframework.ai.azure.openai.AzureOpenAiAudioTranscriptionModel\nimport org.springframework.ai.content.Media\nimport org.springframework.ai.converter.BeanOutputConverter\nimport org.springframework.ai.tool.annotation.Tool\nimport org.springframework.ai.tool.annotation.ToolParam\nimport org.springframework.util.MimeTypeUtils\n\nprintln(\"✅ Dependencies loaded\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependencies loaded\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Large Language Models\n",
    "\n",
    "### 1.1 What an LLM Is\n",
    "\n",
    "An LLM is a pre-trained pattern-matching model that generates text, audio, or structured data by predicting the next token in a sequence. It synthesises personalised answers from patterns it absorbed during training rather than looking up exact facts.\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- **Not a database:** no built-in lookups for real-time or private data\n",
    "- **Probabilistic nature:** temperature and sampling parameters influence creativity versus determinism\n",
    "- **Context-aware operation:** the model only \"remembers\" the tokens you send in the current request\n",
    "- **Stateless interaction:** nothing persists across calls unless you resend it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Token-by-Token Generation\n",
    "\n",
    "Every response is emitted token by token. Tokens are ~4 characters on average, and both prompt and response tokens count towards usage quotas.\n",
    "\n",
    "Keep interactions efficient by:\n",
    "- Chunking large documents instead of pasting them wholesale\n",
    "- Preferring retrieval strategies (RAG) over monolithic prompts\n",
    "- Monitoring prompt/response token counts for cost and latency control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.3 Stateless Conversations\n\nBecause LLM APIs are stateless, you must resend prior turns to maintain context:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:12:31.211808Z",
     "start_time": "2025-10-18T08:12:31.171444Z"
    }
   },
   "source": "// Demonstrating stateless conversation with message history\nval history = listOf(\n    UserMessage(\"My name is Alex\"),\n    AssistantMessage(\"Nice to meet you, Alex!\"),\n    UserMessage(\"What's my name?\")\n)\n\n// When sent to chatModel: chatModel.call(new Prompt(history))\n// Expected output: \"Your name is Alex.\"\n\nprintln(\"Message history created:\")\nhistory.forEach { msg ->\n    println(\"  ${msg.javaClass.simpleName}: ${msg.text}\")\n}",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message history created:\n",
      "  UserMessage: My name is Alex\n",
      "  AssistantMessage: Nice to meet you, Alex!\n",
      "  UserMessage: What's my name?\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Messages and Prompt Engineering\n",
    "\n",
    "### 2.1 Message Roles\n",
    "\n",
    "Spring AI encodes prompts as structured messages with explicit roles:\n",
    "\n",
    "- **System role:** global guidance (\"You are VoyagerMate, an accessible travel advisor.\")\n",
    "- **User role:** the traveller's request\n",
    "- **Assistant role:** previous model replies that maintain conversational flow\n",
    "- **Tool role:** results returned by external functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Constructing a Prompt\n",
    "\n",
    "Let's build a prompt using Spring AI's message types and templates:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:12:58.083656Z",
     "start_time": "2025-10-18T08:12:58.034006Z"
    }
   },
   "source": "// Creating a system prompt with template\nval systemText = \"\"\"\n    You are VoyagerMate, a helpful travel assistant.\n    Focus on logistics, budgets, and local insight.\n    Reply in the style of {voice}.\n\"\"\".trimIndent()\n\nval systemTemplate = SystemPromptTemplate(systemText)\nval systemMessage = systemTemplate.createMessage(mapOf(\"voice\" to \"enthusiastic local guide\"))\n\nval userMessage = UserMessage(\"Plan a 3-day spring trip to Rome with mobility support.\")\n\n// Combine messages into a prompt\nval prompt = Prompt(listOf(systemMessage, userMessage))\n\nprintln(\"System message: ${systemMessage.text}\")\nprintln()\nprintln(\"User message: ${userMessage.text}\")\n\n// chatModel.call(prompt) would send this to the LLM",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System message: You are VoyagerMate, a helpful travel assistant.\n",
      "Focus on logistics, budgets, and local insight.\n",
      "Reply in the style of enthusiastic local guide.\n",
      "\n",
      "User message: Plan a 3-day spring trip to Rome with mobility support.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Four Building Blocks of Effective Prompts\n",
    "\n",
    "1. **Instructions:** exactly what the model should produce\n",
    "2. **External context:** traveller preferences, budgets, constraints\n",
    "3. **User input:** the direct question or task\n",
    "4. **Output cues:** required structure (tables, JSON schema, markdown sections)\n",
    "\n",
    "**Practical tips:**\n",
    "\n",
    "- **Be specific:** \"List 5 family-friendly activities in Tokyo for April\" beats \"Tell me about Tokyo.\"\n",
    "- **Communicate constraints:** budgets, accessibility needs, dietary choices\n",
    "- **Provide structure:** define sections such as `## Morning`, `## Afternoon`, or share JSON scaffolding\n",
    "- **Iterate:** capture edge cases, test tone, and refine temperature settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Context Engineering\n",
    "\n",
    "When you add instructions, examples, tools, and retrieved documents, you are performing **context engineering**.\n",
    "\n",
    "- **Right altitude:** avoid vague goals (\"be helpful\") or hyper-specific micromanagement\n",
    "- **Minimal toolset:** only register the functions you expect to use\n",
    "- **Few-shot examples:** offer 2–3 high-quality samples instead of exhaustive lists\n",
    "- **Just-in-time data:** fetch snippets when needed instead of saturating the prompt window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prompt Templates and Reuse\n",
    "\n",
    "Spring AI's `PromptTemplate` decouples static prompt structure from dynamic values:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:05:25.466043Z",
     "start_time": "2025-10-18T08:05:25.428761Z"
    }
   },
   "source": "// Using PromptTemplate for reusable prompts\n// In Java: var template = new PromptTemplate(\"Explain {season} travel in {destination}\");\nval template = PromptTemplate(\"Explain {season} travel in {destination}\")\n\nval autumnBarcelonaPrompt = template.create(\n    mapOf(\n        \"season\" to \"autumn\",\n        \"destination\" to \"Barcelona\"\n    )\n)\n\nprintln(\"Template: Explain {season} travel in {destination}\")\nprintln()\nautumnBarcelonaPrompt.instructions.forEach { msg ->\n    println(\"Resolved: ${msg.text}\")\n}",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Explain {season} travel in {destination}\n",
      "\n",
      "Resolved: Explain autumn travel in Barcelona\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Templates can also be stored as external resources to version them alongside code, making it easier for product and content teams to collaborate."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Working with Spring AI ChatClient\n",
    "\n",
    "### 4.1 Architectural Overview\n",
    "\n",
    "`ChatClient` wraps a provider-specific `ChatModel` with fluent APIs, default options, advisors, and tool orchestration.\n",
    "\n",
    "```\n",
    "┌─────────────────┐\n",
    "│ Your Service    │  (ChatClient)\n",
    "└────────┬────────┘\n",
    "         │\n",
    "┌────────▼────────┐\n",
    "│ Spring AI Layer │  Prompt assembly, retries,\n",
    "│                 │  observability, advisors\n",
    "└────────┬────────┘\n",
    "         │\n",
    "┌────────▼────────┐\n",
    "│ Provider API    │  Azure OpenAI, OpenAI, Anthropic...\n",
    "└─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Fluent Usage Patterns\n",
    "\n",
    "Here are the common ChatClient patterns (Java-style, executable in Kotlin):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:05:37.739803Z",
     "start_time": "2025-10-18T08:05:37.585275Z"
    }
   },
   "source": "// ChatClient fluent API demonstration\n\n// Since we don't have a configured ChatClient in notebook, let's demonstrate the pattern structure\nclass MockChatClient {\n    fun prompt() = PromptBuilder()\n    \n    class PromptBuilder {\n        private var userText = \"\"\n        private var temp: Double? = null\n        \n        fun user(text: String): PromptBuilder {\n            userText = text\n            return this\n        }\n        \n        fun options(temperature: Double): PromptBuilder {\n            temp = temperature\n            return this\n        }\n        \n        fun call(): CallResponse {\n            return CallResponse(userText, temp)\n        }\n        \n        fun stream(): StreamResponse {\n            return StreamResponse(userText)\n        }\n    }\n    \n    class CallResponse(private val prompt: String, private val temp: Double?) {\n        fun content(): String = \"Response to: $prompt (temp: ${temp ?: \"default\"})\"\n        fun <T> entity(clazz: Class<T>): T? = null // Would convert to type\n    }\n    \n    class StreamResponse(private val prompt: String) {\n        fun content() = prompt.split(\" \").asSequence()\n    }\n}\n\nval chatClient = MockChatClient()\n\n// Pattern 1: Simple call\nval answer = chatClient.prompt()\n    .user(\"Best time to visit Santorini?\")\n    .call()\n    .content()\nprintln(\"Simple call: $answer\")\n\n// Pattern 2: With temperature\nval creative = chatClient.prompt()\n    .user(\"Suggest quirky activities\")\n    .options(1.1)\n    .call()\n    .content()\nprintln(\"With options: $creative\")\n\n// Pattern 3: Streaming\nval stream = chatClient.prompt()\n    .user(\"Tell me about Iceland\")\n    .stream()\n    .content()\nprintln(\"Streaming: ${stream.take(3).joinToString(\" \")}...\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Metadata and Resilience\n",
    "\n",
    "Extract metadata from responses for observability:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:05:49.100269Z",
     "start_time": "2025-10-18T08:05:48.991112Z"
    }
   },
   "source": "// Extracting metadata - working simulation\n\n// Simulate the response structure from ChatClient\ndata class TokenUsage(\n    val promptTokens: Int,\n    val completionTokens: Int,\n    val totalTokens: Int\n)\n\ndata class ResponseMetadata(\n    val model: String,\n    val usage: TokenUsage\n)\n\ndata class ChatResponse(\n    val content: String,\n    val metadata: ResponseMetadata\n)\n\n// Simulate what you'd get from: chatClient.prompt().user(...).call().chatResponse()\nval response = ChatResponse(\n    content = \"Paris is beautiful in spring with mild weather and blooming gardens.\",\n    metadata = ResponseMetadata(\n        model = \"gpt-4o\",\n        usage = TokenUsage(\n            promptTokens = 25,\n            completionTokens = 50,\n            totalTokens = 75\n        )\n    )\n)\n\n// Extract and use the metadata\nprintln(\"Response: ${response.content}\")\nprintln()\nprintln(\"Metadata:\")\nprintln(\"  Model: ${response.metadata.model}\")\nprintln(\"  Prompt tokens: ${response.metadata.usage.promptTokens}\")\nprintln(\"  Completion tokens: ${response.metadata.usage.completionTokens}\")\nprintln(\"  Total tokens: ${response.metadata.usage.totalTokens}\")\nprintln()\nprintln(\"Cost calculation: ${response.metadata.usage.totalTokens} tokens * \\$0.0001 = $${response.metadata.usage.totalTokens * 0.0001}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Paris is beautiful in spring with mild weather and blooming gardens.\n",
      "\n",
      "Metadata:\n",
      "  Model: gpt-4o\n",
      "  Prompt tokens: 25\n",
      "  Completion tokens: 50\n",
      "  Total tokens: 75\n",
      "\n",
      "Cost calculation: 75 tokens * $0.0001 = $0.007500000000000001\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Default Configuration\n",
    "\n",
    "Configure ChatClient with defaults to keep tone, tooling, and memory consistent:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T07:21:05.255631Z",
     "start_time": "2025-10-18T07:21:05.246082Z"
    }
   },
   "source": "// ChatClient builder pattern - ACTUAL EXECUTION\n\nclass ChatClientBuilder {\n    private var systemPrompt: String = \"\"\n    private val tools = mutableListOf<String>()\n    private val advisors = mutableListOf<String>()\n    private var temperature: Double = 0.7\n    \n    fun defaultSystem(prompt: String): ChatClientBuilder {\n        systemPrompt = prompt\n        return this\n    }\n    \n    fun defaultTools(vararg toolNames: String): ChatClientBuilder {\n        tools.addAll(toolNames)\n        return this\n    }\n    \n    fun defaultAdvisors(vararg advisorNames: String): ChatClientBuilder {\n        advisors.addAll(advisorNames)\n        return this\n    }\n    \n    fun defaultTemperature(temp: Double): ChatClientBuilder {\n        temperature = temp\n        return this\n    }\n    \n    fun build(): ConfiguredClient {\n        return ConfiguredClient(systemPrompt, tools, advisors, temperature)\n    }\n}\n\ndata class ConfiguredClient(\n    val systemPrompt: String,\n    val tools: List<String>,\n    val advisors: List<String>,\n    val temperature: Double\n) {\n    fun showConfig() {\n        println(\"ChatClient Configuration:\")\n        println(\"  System prompt: $systemPrompt\")\n        println(\"  Tools: ${tools.joinToString(\", \")}\")\n        println(\"  Advisors: ${advisors.joinToString(\", \")}\")\n        println(\"  Temperature: $temperature\")\n    }\n}\n\n// Execute: Build a ChatClient\nprintln(\"=== Building ChatClient ===\")\nprintln()\n\nval client = ChatClientBuilder()\n    .defaultSystem(\"You are VoyagerMate, an expert travel assistant.\")\n    .defaultTools(\"findAttractions\", \"estimateBudget\", \"checkWeather\")\n    .defaultAdvisors(\"MemoryAdvisor\", \"RAGAdvisor\", \"LoggingAdvisor\")\n    .defaultTemperature(0.7)\n    .build()\n\nclient.showConfig()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Multimodal Interactions\n",
    "\n",
    "### 5.1 Image Analysis\n",
    "\n",
    "GPT-4o-style models accept images alongside text, enabling visual travel insights:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:27:41.606022Z",
     "start_time": "2025-10-18T08:27:41.484593Z"
    }
   },
   "source": "// Image analysis with Media builder - ACTUAL EXECUTION\n\n// Media builder implementation\ndata class MediaObject(val mimeType: String, val data: ByteArray, val size: Int) {\n    companion object {\n        fun builder() = MediaBuilder()\n    }\n    \n    class MediaBuilder {\n        private var mimeType: String = \"\"\n        private var data: ByteArray = byteArrayOf()\n        \n        fun mimeType(type: String): MediaBuilder {\n            mimeType = type\n            return this\n        }\n        \n        fun data(bytes: ByteArray): MediaBuilder {\n            data = bytes\n            return this\n        }\n        \n        fun build() = MediaObject(mimeType, data, data.size)\n    }\n}\n\n// UserMessage with media builder\ndata class MultimodalMessage(val text: String, val media: MediaObject?) {\n    companion object {\n        fun builder() = Builder()\n    }\n    \n    class Builder {\n        private var text: String = \"\"\n        private var media: MediaObject? = null\n        \n        fun text(t: String): Builder {\n            text = t\n            return this\n        }\n        \n        fun media(m: MediaObject): Builder {\n            media = m\n            return this\n        }\n        \n        fun build() = MultimodalMessage(text, media)\n    }\n}\n\n// Execute: Build a multimodal message\nprintln(\"=== Multimodal Message Builder ===\")\nprintln()\n\n// Simulate image data\nval imageBytes = ByteArray(1024) { it.toByte() }  // 1KB fake image\n\n// Build media\nval media = MediaObject.builder()\n    .mimeType(\"image/jpeg\")\n    .data(imageBytes)\n    .build()\n\nprintln(\"1. Created Media:\")\nprintln(\"   MIME type: ${media.mimeType}\")\nprintln(\"   Size: ${media.size} bytes\")\nprintln()\n\n// Build message with media\nval message = MultimodalMessage.builder()\n    .text(\"What destination is shown in this photo?\")\n    .media(media)\n    .build()\n\nprintln(\"2. Created UserMessage:\")\nprintln(\"   Text: ${message.text}\")\nprintln(\"   Has media: ${message.media != null}\")\nprintln(\"   Media size: ${message.media?.size} bytes\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multimodal Message Builder ===\n",
      "\n",
      "1. Created Media:\n",
      "   MIME type: image/jpeg\n",
      "   Size: 1024 bytes\n",
      "\n",
      "2. Created UserMessage:\n",
      "   Text: What destination is shown in this photo?\n",
      "   Has media: true\n",
      "   Media size: 1024 bytes\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Audio Input and Output\n",
    "\n",
    "Process audio notes and generate speech responses:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:27:47.251119Z",
     "start_time": "2025-10-18T08:27:47.088087Z"
    }
   },
   "source": "// Audio transcription - ACTUAL EXECUTION\n\nimport org.springframework.core.io.ByteArrayResource\n\nclass AudioTranscriptionService {\n    fun transcribe(audioResource: ByteArrayResource): String {\n        // Simulate Whisper API transcription\n        val size = audioResource.contentLength()\n        return when {\n            size < 1000 -> \"Short audio: I want to visit Paris.\"\n            size < 5000 -> \"Medium audio: I want to plan a trip to Paris in spring for 5 days with a budget of 2000 euros.\"\n            else -> \"Long audio: I'm planning a European vacation and I'd like to visit Paris in the spring, probably for about 5 days. My budget is around 2000 euros. Can you help me plan the perfect itinerary?\"\n        }\n    }\n    \n    fun processWithLLM(transcript: String, userPrompt: String): String {\n        // Simulate LLM processing the transcript\n        val hasCity = transcript.contains(\"Paris\", ignoreCase = true)\n        val hasDuration = Regex(\"\\\\d+\\\\s*days?\").find(transcript) != null\n        val hasBudget = Regex(\"\\\\d+\\\\s*(euros?|dollars?)\").find(transcript) != null\n        \n        return buildString {\n            append(\"I can help you plan a trip to Paris! Based on your note:\\n\")\n            if (hasDuration) append(\"- Duration: 5 days\\n\")\n            if (hasBudget) append(\"- Budget: 2000 euros\\n\")\n            append(\"- Season: Spring (perfect for Paris!)\\n\")\n            append(\"\\nI'll create a detailed itinerary for you.\")\n        }\n    }\n}\n\n// Execute: Transcribe and process audio\nprintln(\"=== Audio Transcription Demo ===\")\nprintln()\n\nval transcriptionService = AudioTranscriptionService()\n\n// Test different audio sizes\nval audioSizes = listOf(500, 2500, 8000)\n\naudioSizes.forEach { size ->\n    val audioBytes = ByteArray(size) { it.toByte() }\n    val audioResource = ByteArrayResource(audioBytes)\n    \n    println(\"Audio ${size} bytes:\")\n    \n    // Transcribe\n    val transcript = transcriptionService.transcribe(audioResource)\n    println(\"  Transcript: $transcript\")\n    \n    // Process with LLM\n    val response = transcriptionService.processWithLLM(transcript, \"Help plan this trip\")\n    println(\"  LLM Response: ${response.lines().first()}\")\n    println()\n}",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Audio Transcription Demo ===\n",
      "\n",
      "Audio 500 bytes:\n",
      "  Transcript: Short audio: I want to visit Paris.\n",
      "  LLM Response: I can help you plan a trip to Paris! Based on your note:\n",
      "\n",
      "Audio 2500 bytes:\n",
      "  Transcript: Medium audio: I want to plan a trip to Paris in spring for 5 days with a budget of 2000 euros.\n",
      "  LLM Response: I can help you plan a trip to Paris! Based on your note:\n",
      "\n",
      "Audio 8000 bytes:\n",
      "  Transcript: Long audio: I'm planning a European vacation and I'd like to visit Paris in the spring, probably for about 5 days. My budget is around 2000 euros. Can you help me plan the perfect itinerary?\n",
      "  LLM Response: I can help you plan a trip to Paris! Based on your note:\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Structured Outputs\n",
    "\n",
    "### 6.1 Why Structured Outputs Matter\n",
    "\n",
    "Prompting for JSON is unreliable because models add prose or omit fields. OpenAI's structured output mode constrains generation using JSON Schema so every field matches your specification.\n",
    "\n",
    "Let's create a typed itinerary structure:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:27:54.099654Z",
     "start_time": "2025-10-18T08:27:54.042324Z"
    }
   },
   "source": "// Typed models for structured outputs\n\ndata class ItineraryPlan(\n    val destinationOverview: String,\n    val highlights: List<String>,\n    val dailySchedule: List<ItineraryDay>,\n    val bookingReminders: List<String>,\n    val estimatedBudget: Double\n)\n\ndata class ItineraryDay(\n    val day: String,\n    val theme: String,\n    val activities: List<String>,\n    val diningRecommendation: String\n)\n\nprintln(\"Structured output models defined\")\nprintln()\nprintln(\"ItineraryPlan fields:\")\nprintln(\"  - destinationOverview: String\")\nprintln(\"  - highlights: List<String>\")\nprintln(\"  - dailySchedule: List<ItineraryDay>\")\nprintln(\"  - bookingReminders: List<String>\")\nprintln(\"  - estimatedBudget: Double\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured output models defined\n",
      "\n",
      "ItineraryPlan fields:\n",
      "  - destinationOverview: String\n",
      "  - highlights: List<String>\n",
      "  - dailySchedule: List<ItineraryDay>\n",
      "  - bookingReminders: List<String>\n",
      "  - estimatedBudget: Double\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:27:57.539028Z",
     "start_time": "2025-10-18T08:27:57.324305Z"
    }
   },
   "source": "// BeanOutputConverter - actual working example\n\n// Create a converter for our model type\nval converter = BeanOutputConverter(ItineraryPlan::class.java)\n\n// Get the JSON schema that would be sent to the model\nval schema = converter.format\n\nprintln(\"BeanOutputConverter Example:\")\nprintln()\nprintln(\"1. Created converter for ItineraryPlan\")\nprintln(\"2. Generated JSON Schema:\")\nprintln(schema)\nprintln()\n\n// Simulate a JSON response from the model\nval mockJsonResponse = \"\"\"\n{\n  \"destinationOverview\": \"Rome offers ancient history, world-class cuisine, and stunning architecture\",\n  \"highlights\": [\"Colosseum\", \"Vatican Museums\", \"Trevi Fountain\"],\n  \"dailySchedule\": [\n    {\n      \"day\": \"Day 1\",\n      \"theme\": \"Ancient Rome\",\n      \"activities\": [\"Visit Colosseum\", \"Walk Roman Forum\", \"Explore Palatine Hill\"],\n      \"diningRecommendation\": \"Traditional trattoria in Trastevere\"\n    }\n  ],\n  \"bookingReminders\": [\"Book Colosseum tickets in advance\", \"Reserve Vatican tour\"],\n  \"estimatedBudget\": 750.0\n}\n\"\"\".trimIndent()\n\n// Convert JSON to typed object\nval itinerary = converter.convert(mockJsonResponse)\n\nprintln(\"3. Converted JSON response to typed object:\")\nprintln(\"   Destination: ${itinerary.destinationOverview}\")\nprintln(\"   Highlights: ${itinerary.highlights.joinToString(\", \")}\")\nprintln(\"   Budget: $${itinerary.estimatedBudget}\")\nprintln(\"   Days: ${itinerary.dailySchedule.size}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeanOutputConverter Example:\n",
      "\n",
      "1. Created converter for ItineraryPlan\n",
      "2. Generated JSON Schema:\n",
      "Your response should be in JSON format.\n",
      "Do not include any explanations, only provide a RFC8259 compliant JSON response following this format without deviation.\n",
      "Do not include markdown code blocks in your response.\n",
      "Remove the ```json markdown from the output.\n",
      "Here is the JSON Schema instance your output must adhere to:\n",
      "```{\n",
      "  \"$schema\" : \"https://json-schema.org/draft/2020-12/schema\",\n",
      "  \"type\" : \"object\",\n",
      "  \"properties\" : {\n",
      "    \"bookingReminders\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"items\" : {\n",
      "        \"type\" : \"string\"\n",
      "      }\n",
      "    },\n",
      "    \"dailySchedule\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"items\" : {\n",
      "        \"type\" : \"object\",\n",
      "        \"properties\" : {\n",
      "          \"activities\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"items\" : {\n",
      "              \"type\" : \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"day\" : {\n",
      "            \"type\" : \"string\"\n",
      "          },\n",
      "          \"diningRecommendation\" : {\n",
      "            \"type\" : \"string\"\n",
      "          },\n",
      "          \"theme\" : {\n",
      "            \"type\" : \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\" : [ \"activities\", \"day\", \"diningRecommendation\", \"theme\" ],\n",
      "        \"additionalProperties\" : false\n",
      "      }\n",
      "    },\n",
      "    \"destinationOverview\" : {\n",
      "      \"type\" : \"string\"\n",
      "    },\n",
      "    \"estimatedBudget\" : {\n",
      "      \"type\" : \"number\"\n",
      "    },\n",
      "    \"highlights\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"items\" : {\n",
      "        \"type\" : \"string\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"required\" : [ \"bookingReminders\", \"dailySchedule\", \"destinationOverview\", \"estimatedBudget\", \"highlights\" ],\n",
      "  \"additionalProperties\" : false\n",
      "}```\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "java.lang.RuntimeException",
     "evalue": "com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `Line_35_jupyter$ItineraryPlan` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 2, column: 3]",
     "output_type": "error",
     "traceback": [
      "java.lang.RuntimeException: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `Line_35_jupyter$ItineraryPlan` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)",
      " at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 2, column: 3]",
      "\tat org.springframework.ai.converter.BeanOutputConverter.convert(BeanOutputConverter.java:194)",
      "\tat Line_36_jupyter.<init>(Line_36.jupyter.kts:35) at Cell In[31], line 35",
      "\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:483)",
      "\tat kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.evalWithConfigAndOtherScriptsResults(BasicJvmScriptEvaluator.kt:122)",
      "\tat kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.invoke$suspendImpl(BasicJvmScriptEvaluator.kt:48)",
      "\tat kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.invoke(BasicJvmScriptEvaluator.kt)",
      "\tat kotlin.script.experimental.jvm.BasicJvmReplEvaluator.eval(BasicJvmReplEvaluator.kt:49)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.InternalEvaluatorImpl$eval$resultWithDiagnostics$1.invokeSuspend(InternalEvaluatorImpl.kt:137)",
      "\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:34)",
      "\tat kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:100)",
      "\tat kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:263)",
      "\tat kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:95)",
      "\tat kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:69)",
      "\tat kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)",
      "\tat kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:47)",
      "\tat kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.InternalEvaluatorImpl.eval(InternalEvaluatorImpl.kt:137)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.CellExecutorImpl.execute_L4Nmkdk$lambda$0$0(CellExecutorImpl.kt:80)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.withHost(ReplForJupyterImpl.kt:791)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.CellExecutorImpl.execute-L4Nmkdk(CellExecutorImpl.kt:78)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.execution.CellExecutor.execute-L4Nmkdk$default(CellExecutor.kt:14)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.evaluateUserCode-wNURfNM(ReplForJupyterImpl.kt:616)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.evalExImpl(ReplForJupyterImpl.kt:474)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.evalEx$lambda$0(ReplForJupyterImpl.kt:468)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.withEvalContext(ReplForJupyterImpl.kt:450)",
      "\tat org.jetbrains.kotlinx.jupyter.repl.impl.ReplForJupyterImpl.evalEx(ReplForJupyterImpl.kt:467)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.processExecuteRequest$lambda$0$0$0(IdeCompatibleMessageRequestProcessor.kt:160)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.BlockingSubstitutionEngine.withDataSubstitution(SubstitutionEngine.kt:70)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.StreamSubstitutionManager.withSubstitutedStreams(StreamSubstitutionManager.kt:118)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.withForkedIn(IdeCompatibleMessageRequestProcessor.kt:350)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.evalWithIO$lambda$0$0(IdeCompatibleMessageRequestProcessor.kt:363)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.BlockingSubstitutionEngine.withDataSubstitution(SubstitutionEngine.kt:70)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.StreamSubstitutionManager.withSubstitutedStreams(StreamSubstitutionManager.kt:118)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.withForkedErr(IdeCompatibleMessageRequestProcessor.kt:340)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.evalWithIO$lambda$0(IdeCompatibleMessageRequestProcessor.kt:362)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.BlockingSubstitutionEngine.withDataSubstitution(SubstitutionEngine.kt:70)",
      "\tat org.jetbrains.kotlinx.jupyter.streams.StreamSubstitutionManager.withSubstitutedStreams(StreamSubstitutionManager.kt:118)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.withForkedOut(IdeCompatibleMessageRequestProcessor.kt:333)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.evalWithIO(IdeCompatibleMessageRequestProcessor.kt:361)",
      "\tat org.jetbrains.kotlinx.jupyter.messaging.IdeCompatibleMessageRequestProcessor.processExecuteRequest$lambda$0$0(IdeCompatibleMessageRequestProcessor.kt:159)",
      "\tat org.jetbrains.kotlinx.jupyter.execution.JupyterExecutorImpl$Task.execute(JupyterExecutorImpl.kt:41)",
      "\tat org.jetbrains.kotlinx.jupyter.execution.JupyterExecutorImpl.executorThread$lambda$0(JupyterExecutorImpl.kt:81)",
      "\tat kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30)",
      "Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `Line_35_jupyter$ItineraryPlan` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)",
      " at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 2, column: 3]",
      "\tat com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)",
      "\tat com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1915)",
      "\tat com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:415)",
      "\tat com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1402)",
      "\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1514)",
      "\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:340)",
      "\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:177)",
      "\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)",
      "\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4971)",
      "\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3887)",
      "\tat org.springframework.ai.converter.BeanOutputConverter.convert(BeanOutputConverter.java:189)",
      "\t... 44 more",
      "",
      "java.lang.RuntimeException: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `Line_35_jupyter$ItineraryPlan` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)",
      " at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 2, column: 3]",
      "at Cell In[31], line 35"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Tool Calling with Spring AI\n",
    "\n",
    "### 7.1 Why Tools Matter\n",
    "\n",
    "LLMs cannot access live weather, reservations, or private customer data. **Tool calling** lets the model request application functions whenever it needs extra information or actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 7.2 Defining Tools\n\nTools are methods annotated with `@Tool` that the LLM can invoke when it needs external data or actions:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:28:08.039742Z",
     "start_time": "2025-10-18T08:28:07.953653Z"
    }
   },
   "source": "// Tool calling simulation\n\nclass VoyagerToolsSimulation {\n    private val attractionData = mapOf(\n        \"Rome\" to listOf(\"Colosseum\", \"Vatican Museums\", \"Trevi Fountain\", \"Pantheon\"),\n        \"Tokyo\" to listOf(\"Senso-ji\", \"Tokyo Skytree\", \"Meiji Shrine\", \"Shibuya\"),\n        \"Barcelona\" to listOf(\"Sagrada Familia\", \"Park Güell\", \"La Rambla\")\n    )\n    \n    // Would have @Tool annotation in production\n    fun findAttractions(city: String, limit: Int = 5): String {\n        val attractions = attractionData[city] ?: return \"No data for $city\"\n        return attractions.take(limit).joinToString(\", \")\n    }\n    \n    fun estimateBudget(city: String, days: Int): Double {\n        val dailyRates = mapOf(\"Rome\" to 150.0, \"Tokyo\" to 200.0, \"Barcelona\" to 130.0)\n        return (dailyRates[city] ?: 100.0) * days\n    }\n}\n\nval tools = VoyagerToolsSimulation()\n\n// Test the tools\nprintln(\"Tool: findAttractions\")\nprintln(\"  Rome (top 3): ${tools.findAttractions(\"Rome\", 3)}\")\nprintln(\"  Tokyo (all): ${tools.findAttractions(\"Tokyo\")}\")\nprintln()\n\nprintln(\"Tool: estimateBudget\")\nprintln(\"  Rome, 5 days: $${tools.estimateBudget(\"Rome\", 5)}\")\nprintln(\"  Tokyo, 7 days: $${tools.estimateBudget(\"Tokyo\", 7)}\")\nprintln()\n\nprintln(\"LLM calls tools automatically when needed\")\nprintln(\"See: VoyagerTools.java in /src\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: findAttractions\n",
      "  Rome (top 3): Colosseum, Vatican Museums, Trevi Fountain\n",
      "  Tokyo (all): Senso-ji, Tokyo Skytree, Meiji Shrine, Shibuya\n",
      "\n",
      "Tool: estimateBudget\n",
      "  Rome, 5 days: $750.0\n",
      "  Tokyo, 7 days: $1400.0\n",
      "\n",
      "LLM calls tools automatically when needed\n",
      "See: VoyagerTools.java in /src\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Tool Context and Direct Returns\n",
    "\n",
    "- Use `ToolContext` to pass hidden operational data (tenant IDs, request IDs) that should not live in the model prompt\n",
    "- Set `returnDirect = true` when the tool output should bypass the model, for example returning a generated PDF itinerary or RAG search snippet directly to the caller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Bringing Data to the Model\n",
    "\n",
    "Spring AI supports three complementary strategies:\n",
    "\n",
    "### Fine-tuning\n",
    "Retrains the model with domain-specific data. Expensive and rarely necessary for itinerary planning but helps with niche terminology.\n",
    "\n",
    "### Retrieval-Augmented Generation (RAG)\n",
    "Embeds documents, stores them in a vector database, and injects the top semantic matches into the prompt. This approach keeps prompts concise while grounding answers in current knowledge.\n",
    "\n",
    "Process:\n",
    "1. Extract content\n",
    "2. Split it into coherent chunks\n",
    "3. Embed\n",
    "4. Store the vectors\n",
    "5. At query time, retrieve via similarity\n",
    "6. Compose the augmented prompt\n",
    "7. Call the model\n",
    "\n",
    "### Tool calling\n",
    "Accesses external APIs (weather, flights, loyalty data) and takes actions such as bookings or notifications in real time.\n",
    "\n",
    "**VoyagerMate combines all three:** model priors for general travel knowledge, RAG for curated guides, and tools for live data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Advisors: Cross-Cutting Behaviours\n",
    "\n",
    "Advisors are Spring AI interceptors that modify prompts or responses before they reach the provider:\n",
    "\n",
    "- `QuestionAnswerAdvisor` attaches RAG results from a `VectorStore`\n",
    "- `MessageChatMemoryAdvisor` stores conversational history\n",
    "- `SimpleLoggerAdvisor` prints final prompts, responses, tools, and token metrics\n",
    "\n",
    "**Ordering matters:** add memory first, retrieval second, logging last."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:29:40.779011Z",
     "start_time": "2025-10-18T08:29:40.617006Z"
    }
   },
   "source": "// Advisors - ACTUAL EXECUTION\n\n// Memory Advisor\nclass MemoryAdvisor {\n    private val conversations = mutableMapOf<String, MutableList<String>>()\n    \n    fun addMessage(sessionId: String, message: String) {\n        conversations.getOrPut(sessionId) { mutableListOf() }.add(message)\n    }\n    \n    fun getHistory(sessionId: String) = conversations[sessionId] ?: emptyList()\n    \n    fun augmentPrompt(sessionId: String, newPrompt: String): String {\n        val history = getHistory(sessionId)\n        return if (history.isEmpty()) {\n            newPrompt\n        } else {\n            \"Previous conversation:\\n${history.takeLast(3).joinToString(\"\\n\")}\\n\\nNew message: $newPrompt\"\n        }\n    }\n}\n\n// RAG Advisor\nclass RAGAdvisor {\n    private val documents = listOf(\n        \"Paris has the Eiffel Tower, Louvre Museum, and Arc de Triomphe\",\n        \"Best time to visit Paris is April-June and September-October\",\n        \"Paris metro system is efficient, buy a Navigo pass\",\n        \"Rome features Colosseum, Vatican City, and Trevi Fountain\",\n        \"Tokyo combines modern tech with traditional temples\"\n    )\n    \n    fun retrieveRelevant(query: String, topK: Int = 3): List<String> {\n        return documents\n            .map { doc -> doc to calculateRelevance(doc, query) }\n            .sortedByDescending { it.second }\n            .take(topK)\n            .map { it.first }\n    }\n    \n    private fun calculateRelevance(doc: String, query: String): Int {\n        val queryWords = query.lowercase().split(\" \")\n        return queryWords.count { doc.lowercase().contains(it) }\n    }\n    \n    fun augmentPrompt(query: String, userPrompt: String): String {\n        val relevant = retrieveRelevant(query)\n        return \"Context:\\n${relevant.joinToString(\"\\n\")}\\n\\nQuestion: $userPrompt\"\n    }\n}\n\n// Execute: Use advisors\nprintln(\"=== Advisors Demo ===\")\nprintln()\n\nval memoryAdvisor = MemoryAdvisor()\nval ragAdvisor = RAGAdvisor()\n\n// Simulate a conversation with memory\nval sessionId = \"user-456\"\n\nprintln(\"1. Memory Advisor:\")\nmemoryAdvisor.addMessage(sessionId, \"User: Tell me about Paris\")\nmemoryAdvisor.addMessage(sessionId, \"Assistant: Paris is a beautiful city...\")\n\nval promptWithMemory = memoryAdvisor.augmentPrompt(sessionId, \"What about transportation?\")\nprintln(promptWithMemory)\nprintln()\n\n// Simulate RAG retrieval\nprintln(\"2. RAG Advisor:\")\nval query = \"Paris travel tips\"\nval relevantDocs = ragAdvisor.retrieveRelevant(query)\nprintln(\"   Query: $query\")\nprintln(\"   Retrieved ${relevantDocs.size} documents:\")\nrelevantDocs.forEach { println(\"   - $it\") }\nprintln()\n\nval promptWithRAG = ragAdvisor.augmentPrompt(query, \"How do I get around?\")\nprintln(\"   Augmented prompt:\")\nprintln(promptWithRAG.lines().take(4).joinToString(\"\\n\"))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Advisors Demo ===\n",
      "\n",
      "1. Memory Advisor:\n",
      "Previous conversation:\n",
      "User: Tell me about Paris\n",
      "Assistant: Paris is a beautiful city...\n",
      "\n",
      "New message: What about transportation?\n",
      "\n",
      "2. RAG Advisor:\n",
      "   Query: Paris travel tips\n",
      "   Retrieved 3 documents:\n",
      "   - Paris has the Eiffel Tower, Louvre Museum, and Arc de Triomphe\n",
      "   - Best time to visit Paris is April-June and September-October\n",
      "   - Paris metro system is efficient, buy a Navigo pass\n",
      "\n",
      "   Augmented prompt:\n",
      "Context:\n",
      "Paris has the Eiffel Tower, Louvre Museum, and Arc de Triomphe\n",
      "Best time to visit Paris is April-June and September-October\n",
      "Paris metro system is efficient, buy a Navigo pass\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Putting the Patterns Together\n",
    "\n",
    "### 10.1 Conversational Concierge\n",
    "\n",
    "Building a session-aware chat endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Conversational endpoint simulation - ACTUAL EXECUTION\n\nclass ConversationalChatBot {\n    private val sessionMemory = mutableMapOf<String, MutableList<Pair<String, String>>>()\n    \n    fun chat(userMessage: String, sessionId: String): String {\n        val history = sessionMemory.getOrPut(sessionId) { mutableListOf() }\n        history.add(\"user\" to userMessage)\n        \n        // Simulate response based on context\n        val response = when {\n            userMessage.contains(\"weather\", ignoreCase = true) -> \n                \"Rome has beautiful spring weather, around 20°C (68°F) in May.\"\n            userMessage.contains(\"hotel\", ignoreCase = true) -> \n                \"I recommend staying near Termini Station for easy access to attractions.\"\n            else -> \n                \"I can help with that! (Context: ${history.size - 1} previous messages)\"\n        }\n        \n        history.add(\"assistant\" to response)\n        return response\n    }\n    \n    fun getConversationHistory(sessionId: String) = sessionMemory[sessionId] ?: emptyList()\n}\n\n// Create chatbot\nval chatBot = ConversationalChatBot()\n\n// Execute a conversation\nprintln(\"=== Conversational Chat Demo ===\")\nprintln()\n\nprintln(\"User: Tell me about Rome\")\nval r1 = chatBot.chat(\"Tell me about Rome\", \"session-123\")\nprintln(\"Bot: $r1\")\nprintln()\n\nprintln(\"User: What about the weather?\")\nval r2 = chatBot.chat(\"What about the weather?\", \"session-123\")\nprintln(\"Bot: $r2\")\nprintln()\n\nprintln(\"User: Recommend a hotel\")\nval r3 = chatBot.chat(\"Recommend a hotel\", \"session-123\")\nprintln(\"Bot: $r3\")\nprintln()\n\nprintln(\"=== Full Conversation History ===\")\nchatBot.getConversationHistory(\"session-123\").forEachIndexed { idx, (role, msg) ->\n    println(\"${idx + 1}. ${role.uppercase()}: $msg\")\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Image-to-Itinerary Insight\n",
    "\n",
    "Analyzing travel photos to generate destination recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T07:21:05.449557Z",
     "start_time": "2025-10-18T07:10:56.959461Z"
    }
   },
   "source": "// Image analysis - ACTUAL EXECUTION\n\ndata class DestinationAnalysis(\n    val location: String,\n    val landmarks: List<String>,\n    val bestTimeToVisit: String,\n    val estimatedCost: String,\n    val similarDestinations: List<String>\n)\n\nclass PhotoAnalyzer {\n    private val knownLocations = mapOf(\n        \"eiffel\" to DestinationAnalysis(\n            location = \"Paris, France\",\n            landmarks = listOf(\"Eiffel Tower\", \"Louvre Museum\", \"Arc de Triomphe\"),\n            bestTimeToVisit = \"April-June, September-October\",\n            estimatedCost = \"$150-200 per day\",\n            similarDestinations = listOf(\"London\", \"Rome\", \"Barcelona\")\n        ),\n        \"colosseum\" to DestinationAnalysis(\n            location = \"Rome, Italy\",\n            landmarks = listOf(\"Colosseum\", \"Vatican\", \"Trevi Fountain\"),\n            bestTimeToVisit = \"April-May, September-October\",\n            estimatedCost = \"$120-180 per day\",\n            similarDestinations = listOf(\"Athens\", \"Barcelona\", \"Florence\")\n        ),\n        \"tokyo-tower\" to DestinationAnalysis(\n            location = \"Tokyo, Japan\",\n            landmarks = listOf(\"Tokyo Skytree\", \"Senso-ji Temple\", \"Meiji Shrine\"),\n            bestTimeToVisit = \"March-May, September-November\",\n            estimatedCost = \"$180-250 per day\",\n            similarDestinations = listOf(\"Osaka\", \"Kyoto\", \"Seoul\")\n        )\n    )\n    \n    fun analyzePhoto(photoIdentifier: String): DestinationAnalysis {\n        return knownLocations[photoIdentifier] ?: knownLocations[\"eiffel\"]!!\n    }\n}\n\nval analyzer = PhotoAnalyzer()\n\n// Execute photo analysis\nprintln(\"=== Photo Analysis Demo ===\")\nprintln()\n\nval photos = listOf(\"eiffel\", \"colosseum\", \"tokyo-tower\")\n\nphotos.forEach { photo ->\n    val analysis = analyzer.analyzePhoto(photo)\n    \n    println(\"Photo: $photo\")\n    println(\"   Location: ${analysis.location}\")\n    println(\"   Landmarks: ${analysis.landmarks.joinToString(\", \")}\")\n    println(\"   Best time: ${analysis.bestTimeToVisit}\")\n    println(\"   Daily cost: ${analysis.estimatedCost}\")\n    println(\"   Similar: ${analysis.similarDestinations.take(2).joinToString(\", \")}\")\n    println()\n}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Orchestrated Itinerary Generation\n",
    "\n",
    "Combining RAG, tools, and memory for comprehensive trip planning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Complete system: RAG + Tools + Memory - ACTUAL EXECUTION\n\nclass TravelPlanningSystem {\n    // Tools\n    private val attractions = mapOf(\n        \"Rome\" to listOf(\"Colosseum\", \"Vatican Museums\", \"Trevi Fountain\", \"Pantheon\", \"Spanish Steps\"),\n        \"Tokyo\" to listOf(\"Senso-ji Temple\", \"Tokyo Skytree\", \"Meiji Shrine\", \"Tsukiji Market\"),\n        \"Barcelona\" to listOf(\"Sagrada Familia\", \"Park Güell\", \"La Rambla\", \"Gothic Quarter\")\n    )\n    \n    private val budgets = mapOf(\n        \"Rome\" to 150.0,\n        \"Tokyo\" to 200.0,\n        \"Barcelona\" to 130.0\n    )\n    \n    // RAG documents\n    private val travelGuides = listOf(\n        \"Rome: Ancient capital with 2,800 years of history. Famous for Colosseum and Vatican.\",\n        \"Tokyo: Ultra-modern metropolis blending tradition with innovation. Known for temples and technology.\",\n        \"Barcelona: Gaudi's architectural masterpiece. Mediterranean beaches meet Gothic Quarter.\"\n    )\n    \n    // Memory\n    private val conversationMemory = mutableMapOf<String, MutableList<String>>()\n    \n    fun planTrip(request: String, sessionId: String): Map<String, Any> {\n        // 1. Update memory\n        val history = conversationMemory.getOrPut(sessionId) { mutableListOf() }\n        history.add(\"Request: $request\")\n        \n        // 2. Parse city from request\n        val city = when {\n            request.contains(\"Rome\", ignoreCase = true) -> \"Rome\"\n            request.contains(\"Tokyo\", ignoreCase = true) -> \"Tokyo\"\n            request.contains(\"Barcelona\", ignoreCase = true) -> \"Barcelona\"\n            else -> \"Rome\"\n        }\n        \n        // 3. RAG: Retrieve relevant context\n        val context = travelGuides.filter { it.contains(city) }.firstOrNull() ?: \"\"\n        \n        // 4. Tools: Get data\n        val topAttractions = attractions[city]?.take(3) ?: emptyList()\n        val dailyBudget = budgets[city] ?: 100.0\n        \n        // 5. Parse duration\n        val days = Regex(\"(\\\\d+)\").find(request)?.value?.toInt() ?: 3\n        val totalBudget = dailyBudget * days\n        \n        // 6. Generate itinerary\n        val itinerary = buildMap {\n            put(\"destination\", city)\n            put(\"duration\", \"$days days\")\n            put(\"overview\", context)\n            put(\"topAttractions\", topAttractions)\n            put(\"dailyBudget\", dailyBudget)\n            put(\"totalBudget\", totalBudget)\n            put(\"conversationTurns\", history.size)\n        }\n        \n        history.add(\"Response: Itinerary for $city\")\n        \n        return itinerary\n    }\n}\n\n// Execute the system\nval planningSystem = TravelPlanningSystem()\n\nprintln(\"=== Complete Travel Planning System ===\")\nprintln()\n\n// Test 1: Rome trip\nprintln(\"Request 1: Plan a 5-day trip to Rome\")\nval rome = planningSystem.planTrip(\"Plan a 5-day trip to Rome\", \"user-789\")\nprintln(\"  Destination: ${rome[\"destination\"]}\")\nprintln(\"  Duration: ${rome[\"duration\"]}\")\nprintln(\"  Overview: ${rome[\"overview\"]}\")\nprintln(\"  Top attractions: ${rome[\"topAttractions\"]}\")\nprintln(\"  Daily budget: $${rome[\"dailyBudget\"]}\")\nprintln(\"  Total budget: $${rome[\"totalBudget\"]}\")\nprintln(\"  Conversation: ${rome[\"conversationTurns\"]} turns\")\nprintln()\n\n// Test 2: Tokyo trip (same session)\nprintln(\"Request 2: Actually, what about Tokyo for 7 days?\")\nval tokyo = planningSystem.planTrip(\"Actually, what about Tokyo for 7 days?\", \"user-789\")\nprintln(\"  Destination: ${tokyo[\"destination\"]}\")\nprintln(\"  Duration: ${tokyo[\"duration\"]}\")\nprintln(\"  Total budget: $${tokyo[\"totalBudget\"]}\")\nprintln(\"  Conversation: ${tokyo[\"conversationTurns\"]} turns (memory preserved)\")\nprintln()\n\n// Test 3: Barcelona trip (new session)\nprintln(\"Request 3: Barcelona 3 day trip\")\nval barcelona = planningSystem.planTrip(\"Barcelona 3 day trip\", \"user-999\")\nprintln(\"  Destination: ${barcelona[\"destination\"]}\")\nprintln(\"  Total budget: $${barcelona[\"totalBudget\"]}\")\nprintln(\"  Conversation: ${barcelona[\"conversationTurns\"]} turns (new session)\")\nprintln()\n\nprintln(\"System combines:\")\nprintln(\"  - RAG (travel guide context)\")\nprintln(\"  - Tools (attractions, budget calculation)\")\nprintln(\"  - Memory (conversation history)\")\nprintln(\"  - Structured output (typed response)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nYou have learned the foundations of Spring AI:\n\n- LLM Fundamentals: Stateless, token-based, probabilistic models\n- Prompt Engineering: Message roles, templates, context engineering\n- ChatClient: Fluent API, metadata, streaming, default configuration\n- Multimodal: Image analysis, audio transcription, speech generation\n- Structured Outputs: Type-safe JSON with BeanOutputConverter\n- Tool Calling: Extending LLMs with external functions\n- Data Strategies: Fine-tuning, RAG, tool integration\n- Advisors: Cross-cutting concerns (memory, retrieval, logging)\n- Production Patterns: Conversational APIs, image analysis, orchestration\n\n## References\n\n- [Spring AI ChatClient Reference](https://docs.spring.io/spring-ai/reference/api/chatclient.html)\n- [Spring AI Prompt and Message Reference](https://docs.spring.io/spring-ai/reference/api/prompt.html)\n- [Anthropic: Effective Context Engineering](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)\n- [Spring AI OpenAI Chat (Images and Audio)](https://docs.spring.io/spring-ai/reference/api/chat/openai-chat.html)\n- [OpenAI Structured Outputs Guide](https://platform.openai.com/docs/guides/structured-outputs)\n- [Spring AI Tools API and Function Calling](https://docs.spring.io/spring-ai/reference/api/tools.html)\n\n## Next Steps\n\nContinue to the next notebook: [Agentic Patterns](./agentic-patterns.ipynb) to learn about workflows, agents, and advanced orchestration patterns."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.9.23"
  },
  "ktnbPluginMetadata": {
   "projectLibraries": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
